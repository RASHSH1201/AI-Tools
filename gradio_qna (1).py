# -*- coding: utf-8 -*-
"""gradio_qna.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1APknZu4GOjjRbk6z1W4siVS4QEjh101v
"""

!pip install gradio
!pip install langchain-community


import gradio as gr
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain
from getpass import getpass

import os

# Set your OpenAI API key
api_key = getpass("ðŸ”‘ Enter your OpenAI API key: ")

os.environ["OPENAI_API_KEY"] = api_key

# Set up LangChain components

llm = ChatOpenAI(temperature=0)
memory = ConversationBufferMemory()
conversation = ConversationChain(llm=llm, memory=memory)

# Gradio chatbot function
def chat(user_input):
    return conversation.predict(input=user_input)

# Launch Gradio app
gr.Interface(fn=chat, inputs="text", outputs="text", title="LangChain Chatbot").launch()